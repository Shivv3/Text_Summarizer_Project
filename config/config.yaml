#Defining the artifacts folder: It will create a folder called artifacts and all the generation of the components of the project will get saved into artifacts.
artifacts_root : artifacts

#Preparing the data_ingestion config folder:
data_ingestion:

  #Defining the root directory where everything will be created:
  root_dir: artifacts/data_ingestion
  
  #Defining the source url from where the data will be extracted:
  source_URL: https://github.com/Shivv3/Text_Summarizer_Project/raw/refs/heads/main/summarizer-data.zip

  #Defining the type of the file stored in the local folder:
  local_data_file: artifacts/data_ingestion/data.zip

  #Defining the directory where unzipping will be done:
  unzip_dir: artifacts/data_ingestion


#Preparing the data_validation config folder: If all the required files are present then it will return STATUS_FILE as true:
data_validation:
  #Defining the root directory where everything will be created:
  root_dir: artifacts/data_validation

  #Defining the STATUS_FILE:
  STATUS_FILE: artifacts/data_validation/status.txt

  #Defining the required files:
  ALL_REQUIRED_FILES: ["train","test","validation"]


#Preparing the data_tranformation config: 
data_transformation:
  #Defining the root directory:
  root_dir: artifacts/data_transformation
  
  #defining the data_path: the transformed data will be saved at this path:
  data_path: artifacts/data_ingestion/samsum_dataset

  #defining the name of the tokenizer:
  tokenizer_name: google/pegasus-cnn_dailymail





 

